data=[50,50,47,97,49,3,53,42,26,74,82,62,37,15,70,27,36,35,48,52,63,64]
print(data)
  
-->OUTPUT :: [50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64]

import numpy as np

grades = np.array(data)
print(grades)

-->OUTPUT :: [50 50 47 97 49  3 53 42 26 74 82 62 37 15 70 27 36 35 48 52 63 64]

Note that multiplying a list by 2 creates a new list of twice the length with the original 
sequence of list elements repeated. Multiplying a NumPy array on the other hand performs an element-wise 
calculation in which the array behaves like a vector, so we end up with an array of the same size
in which each element has been multiplied by 2.

The key takeaway from this is that NumPy arrays are specifically designed to support mathematical operations on numeric
data - which makes them more useful for data analysis than a generic list.
print (type(data),'x 2:', data * 2)
print('---')
print (type(grades),'x 2:', grades * 2)

-->OUTPUT :: 

<class 'list'> x 2: [50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64, 50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64]
---
<class 'numpy.ndarray'> x 2: [100 100  94 194  98   6 106  84  52 148 164 124  74  30 140  54  72  70
  96 104 126 128]
  
  You might have spotted that the class type for the numpy array above is a numpy.ndarray. 
  The nd indicates that this is a structure that can consists of multiple dimensions (it can have n dimensions). 
  
  grades.shape
  
  --> OUTPUT :: (22,)
  
  grades.mean()
  
  --> OUTPUT :: 49.18181818181818
  
  # Define an array of study hours
study_hours = [10.0,11.5,9.0,16.0,9.25,1.0,11.5,9.0,8.5,14.5,15.5,
               13.75,9.0,8.0,15.5,8.0,9.0,6.0,10.0,12.0,12.5,12.0]

# Create a 2D array (an array of arrays)
student_data = np.array([study_hours, grades])

# display the array
student_data

 --> OUTPUT ::
 array([[10.  , 11.5 ,  9.  , 16.  ,  9.25,  1.  , 11.5 ,  9.  ,  8.5 ,
        14.5 , 15.5 , 13.75,  9.  ,  8.  , 15.5 ,  8.  ,  9.  ,  6.  ,
        10.  , 12.  , 12.5 , 12.  ],
       [50.  , 50.  , 47.  , 97.  , 49.  ,  3.  , 53.  , 42.  , 26.  ,
        74.  , 82.  , 62.  , 37.  , 15.  , 70.  , 27.  , 36.  , 35.  ,
        48.  , 52.  , 63.  , 64.  ]])

# Show shape of 2D array
student_data.shape

--> OUTPUT :: (2, 22)

# Get the mean value of each sub-array
avg_study = student_data[0].mean()
avg_grade = student_data[1].mean()

print('Average study hours: {:.2f}\nAverage grade: {:.2f}'.format(avg_study, avg_grade))

--> OUTPUT :: 
Average study hours: 10.52
Average grade: 49.18

__________________________________________>Exploring tabular data with Pandas<_________________________________________
_______________________________________________________________________________________________________________________
import pandas as pd

df_students = pd.DataFrame({'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic', 'Jimmie', 
                                     'Rhonda', 'Giovanni', 'Francesca', 'Rajab', 'Naiyana', 'Kian', 'Jenny',
                                     'Jakeem','Helena','Ismat','Anila','Skye','Daniel','Aisha'],
                            'StudyHours':student_data[0],
                            'Grade':student_data[1]})

df_students 

 ---Tabular Data---
 
  	Name	StudyHours	Grade
0	Dan	10.00	50.0
1	Joann	11.50	50.0
2	Pedro	9.00	47.0
3	Rosie	16.00	97.0
4	Ethan	9.25	49.0
5	Vicky	1.00	3.0
6	Frederic	11.50	53.0
7	Jimmie	9.00	42.0
8	Rhonda	8.50	26.0
9	Giovanni	14.50	74.0
10	Francesca	15.50	82.0

 # Get the data for index value 5
df_students.loc[5]

-->OUTPUT ::
Name          Vicky
StudyHours      1.0
Grade           3.0
Name: 5, dtype: object

# Get the rows with index values from 0 to 5 in tabular form
df_students.loc[0:5]

# Get data in the first five rows
df_students.iloc[0:5]

iloc identifies data values in a DataFrame by position,
which extends beyond rows to columns. So for example, you can use
it to find the values for the columns in positions 
1 and 2 in row 0, like this:

df_students.iloc[0,[1,2]]

---output------
StudyHours    10.0
Grade         50.0
Name: 0, dtype: object


df_students.loc[0,'Grade']
-----output-----
50.0

df_students.loc[df_students['Name']=='Aisha']
---or---
df_students[df_students['Name']=='Aisha']
--or--
df_students.query('Name=="Aisha"')
--or--
df_students[df_students.Name == 'Aisha']
------output------
	Name	StudyHours	Grade
21	Aisha	12.0	64.0

-----------------Loading a DataFrame from a file----------------------
_______________________________________________________________________

!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv
df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')
df_students.head()

----output----
--2022-06-18 06:38:05--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 322 [text/plain]
Saving to: ‘grades.csv’

grades.csv          100%[===================>]     322  --.-KB/s    in 0s      

2022-06-18 06:38:05 (11.9 MB/s) - ‘grades.csv’ saved [322/322]

	Name	StudyHours	Grade
0	Dan	10.00	50.0
1	Joann	11.50	50.0
2	Pedro	9.00	47.0
3	Rosie	16.00	97.0
4	Ethan	9.25	49.0
______________________________________________________________________________________________________________________________________________________
 DataFrame contains missing values? You can use the isnull method to identify which individual values are null,
 df_students.isnull()
 ----output---
 	Name	StudyHours	Grade
0	False	False	False
1	False	False	False
2	False	False	False
3	False	False	False

__________________________________________
we can get the sum of missing values for each column, 

df_students.isnull().sum()
----output----
Name          0
StudyHours    1
Grade         2
dtype: int64
_______________________________________________
we can filter the dataframe to include only rows where 
any of the columns (axis 1 of the DataFrame) are null.

df_students[df_students.isnull().any(axis=1)]

---output----



 _______________________________________________________________________________
 One common approach is to impute replacement values. For example, if the number
 of study hours is missing, we could just assume that the student studied for an
 average amount of time and replace the missing value with the mean study hours. 
 
 df_students.StudyHours = df_students.StudyHours.fillna(df_students.StudyHours.mean())
df_students

_________________________________________________________________________________
Alternatively, it might be important to ensure that you only use data you know to be
absolutely correct; so you can drop rows or columns that contains null values by using
the dropna method. In this case, we'll remove rows (axis 0 of the DataFrame) 
where any of the columns contain null values.

df_students = df_students.dropna(axis=0, how='any')
df_students
_________________________________________________________________________________
---------------Explore data in the DataFrame---------------------------
_________________________________________________________________________________
comparing the mean study hours and grades.
# Get the mean study hours using to column name as an index
mean_study = df_students['StudyHours'].mean()

# Get the mean grade using the column name as a property (just to make the point!)
mean_grade = df_students.Grade.mean()

# Print the mean study hours and mean grade
print('Average weekly study hours: {:.2f}\nAverage grade: {:.2f}'.format(mean_study, mean_grade))

---------------output--------------
Average weekly study hours: 10.52
Average grade: 49.18
_________________________________________________________________________________
students who studied for more than the average amount of time.

df_students[df_students.StudyHours > mean_study]
_______________________________________________________________________
average grade for students who undertook more than the average amount of study time.

# What was their mean grade?
df_students[df_students.StudyHours > mean_study].Grade.mean()
__________________________________________________________________________________
create a Pandas Series containing the pass/fail indicator 

passes  = pd.Series(df_students['Grade'] >= 60)
df_students = pd.concat([df_students, passes.rename("Pass")], axis=1)

df_students

 __________________________________________________________________________________
 how many students passed and failed.
 
 print(df_students.groupby(df_students.Pass).Name.count())
 
 -----output---
 Pass
False    15
True      7
Name: Name, dtype: int64
_____________________________________________________________________________________
mean study time and grade for the groups of students who passed and failed the course.

print(df_students.groupby(df_students.Pass)['StudyHours', 'Grade'].mean())

-----output----
     StudyHours      Grade
Pass                        
False    8.783333  38.000000
True    14.250000  73.142857
________________________________________________________________________________
# Create a DataFrame with the data sorted by Grade (descending)
df_students = df_students.sort_values('Grade', ascending=False)

# Show the DataFrame
df_students
_______________________________________________________________________________
